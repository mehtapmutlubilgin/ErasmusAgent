
import gradio as gr
import os
import pandas as pd

# Gerekli kÃ¼tÃ¼phaneler (Hugging Face'e yÃ¼klediÄŸinizden emin olun)
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import ChatPromptTemplate # GÃœNCELLEME 3: Prompt iÃ§in

# GÃœNCELLEME 3: Sistem Åablonu (System Prompt)
SYSTEM_TEMPLATE = """
Sen bir Erasmus+ bilgilendirme uzmanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorusuna sadece ve kesinlikle 
SAÄLANAN KAYNAK METÄ°NLERÄ° kullanarak cevap ver. 
EÄŸer kaynak metinlerde cevap yoksa, "Bu konuda elimde kesin bir bilgi bulunmamaktadÄ±r, 
lÃ¼tfen Ã¼niversitenizin UluslararasÄ± Ä°liÅŸkiler Ofisi'ne danÄ±ÅŸÄ±n." ÅŸeklinde cevapla. 
CevaplarÄ±nÄ± her zaman TÃ¼rkÃ§e olarak ve net bir dille sun.

KAYNAK: {context}
"""

# RAG ZÄ°NCÄ°RÄ°NÄ° BAÅLATMA FONKSÄ°YONU
def setup_rag_chain():
    """RAG zincirini kurar ve dÃ¶ndÃ¼rÃ¼r."""
    
    # 1. API AnahtarÄ±nÄ± YÃ¼kleme (Hugging Face Secrets'tan)
    try:
        GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
        if not GEMINI_API_KEY:
             # EÄŸer anahtar yoksa, hata dÃ¶ndÃ¼r.
             raise ValueError("API anahtarÄ± (GEMINI_API_KEY) Hugging Face Secrets'ta bulunamadÄ±.")
        os.environ["GEMINI_API_KEY"] = GEMINI_API_KEY
    except Exception as e:
        print(f"HATA: API AnahtarÄ± yÃ¼klenemedi: {e}")
        return None
    
    # 2. Veri Setini Okuma (Yerel Dizin)
    try:
        DATA_FILE_PATH = 'erasmus_chatbot_dataset.csv' 
        df = pd.read_csv(DATA_FILE_PATH)
        df['kaynak_metin'] = "Kategori: " + df['kategori'] + ". Soru: " + df['soru'] + ". Cevap: " + df['cevap']
        documents_for_rag = df['kaynak_metin'].tolist()
    except Exception as e:
        print(f"HATA: Veri Seti Okuma BaÅŸarÄ±sÄ±z: {e}")
        return None

    # 3. RAG Mimarisi Kurulumu
    
    # GÃœNCELLEME 1: RecursiveCharacterTextSplitter kullanarak daha iyi parÃ§alama
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,        # Maksimum parÃ§a boyutu
        chunk_overlap=50,      # ParÃ§alarÄ±n Ã¶rtÃ¼ÅŸme miktarÄ± (baÄŸlam kaybÄ±nÄ± Ã¶nler)
        length_function=len,
        is_separator_regex=False,
    )
    texts = text_splitter.create_documents(documents_for_rag)

    # API anahtarÄ±nÄ± doÄŸrudan ilet
    embeddings = GoogleGenerativeAIEmbeddings(
        model="text-embedding-004",
        google_api_key=GEMINI_API_KEY
    )
    db = Chroma.from_documents(texts, embeddings)

    # API anahtarÄ±nÄ± doÄŸrudan ilet
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        temperature=0, # YaratÄ±cÄ±lÄ±ÄŸÄ± azaltÄ±p kesin bilgiye yÃ¶nlendirdik
        google_api_key=GEMINI_API_KEY
    )
    
    # GÃœNCELLEME 3: Prompt Åablonunu OluÅŸturma
    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_TEMPLATE),
        ("human", "{question}"),
    ])

    # GÃœNCELLEME 2 & 3: RetrievalQA Zinciri
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever(k=5), # k deÄŸerini 5'e Ã§Ä±kardÄ±k (Daha fazla baÄŸlam)
        return_source_documents=True,
        # Prompt'u chain_type_kwargs Ã¼zerinden ekleyerek System Prompt'u etkinleÅŸtir
        chain_type_kwargs={
             "prompt": qa_prompt,
             "document_variable_name": "context" # Prompt'taki context deÄŸiÅŸkenini eÅŸleÅŸtirir
        }
    )
    
    print("RAG Zinciri baÅŸarÄ±yla kuruldu ve optimize edildi.")
    return qa_chain

# Global olarak RAG zincirini bir kere yÃ¼kle
qa_chain = setup_rag_chain()

def chatbot_response(message, history):
    """Gelen mesajÄ± RAG zincirine gÃ¶nderir ve cevabÄ± dÃ¶ndÃ¼rÃ¼r."""
    
    if qa_chain is None:
        return "Chatbot kurulumu baÅŸarÄ±sÄ±z oldu. LÃ¼tfen Hugging Face Secrets ve loglarÄ± kontrol edin."

    response = qa_chain({"query": message})
    answer = response['result']
    source_docs = response['source_documents']
    
    # Kaynak Bilgisini HazÄ±rlama
    sources_text = "\n\n***\n**Kaynaklar:**\n"
    for doc in source_docs:
        # Kaynak metin formatÄ±nÄ± daha anlaÅŸÄ±lÄ±r hale getir
        content = doc.page_content.replace('Soru:', 'Soru: ').replace('. Cevap:', ' | Cevap: ')
        sources_text += f"*{content[:150]}...*\n"

    full_response = answer + sources_text
    
    return full_response

# GRADIO ARAYÃœZÃœ
iface = gr.ChatInterface(
    fn=chatbot_response,
    title="ğŸ‡ªğŸ‡º Erasmus RAGent Chatbot (Optimize EdilmiÅŸ)", 
    description="RAG (Retrieval Augmented Generation) ile Erasmus+ Bilgilendirme Sistemi. SorularÄ±nÄ±zÄ± sorabilirsiniz!",
    chatbot=gr.Chatbot(height=500),
    examples=["Erasmus'a kimler baÅŸvurabilir?", "Ã–ÄŸrenim sÃ¼resi ne kadardÄ±r?", "Hibesiz Erasmus yapÄ±labilir mi?"],
    theme="soft"
)

if __name__ == "__main__":
    iface.launch()
