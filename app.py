
# ==============================================================================
# PROJE: Erasmus RAGent Chatbot (Akbank GenAI Bootcamp)
# DOSYA: app.py (Final SÃ¼rÃ¼m - Stabil Ä°Ã§e Aktarma)
# ==============================================================================

import gradio as gr
import os
import pandas as pd
# Ã‡Ã¶zÃ¼m: LangChain'in kararlÄ± Ã§ekirdek kÃ¼tÃ¼phaneleri
from langchain_core.documents import Document 
from langchain_core.prompts import ChatPromptTemplate 
from langchain_core.language_models.chat_models import BaseChatModel 
from langchain_core.embeddings import Embeddings 

# LangChain Ä°Ã§e AktarmalarÄ±: Zincir ve Modeller
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma 
from langchain.chains import RetrievalQA # Tekrar deneme

# ==============================================================================
# RAG PARAMETRELERÄ° VE OPTÄ°MÄ°ZASYONLARI
# ==============================================================================

SYSTEM_TEMPLATE = """
Sen bir Erasmus+ bilgilendirme uzmanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorusuna, Ã¶ncelikle 
SAÄžLANAN KAYNAK METÄ°NLERÄ° kullanarak cevap ver. 
CevaplarÄ±nÄ± her zaman TÃ¼rkÃ§e olarak ve net bir dille sun.

EÄŸer kaynak metinlerde cevap yoksa:
1. Konuyla ilgili genel, gÃ¼venilir bilgin varsa, "Kaynaklarda doÄŸrudan cevap bulunmamaktadÄ±r, ancak genel bilgi ÅŸÃ¶yledir:" diyerek cevap verebilirsin.
2. HiÃ§bir bilgin yoksa, "Bu konuda elimde yeterli ve kesin bir bilgi bulunmamaktadÄ±r, lÃ¼tfen Ã¼niversitenizin UluslararasÄ± Ä°liÅŸkiler Ofisi'ne danÄ±ÅŸÄ±n." ÅŸeklinde kibarca cevapla.

KAYNAK: {context}
"""

# ==============================================================================
# RAG ZÄ°NCÄ°RÄ°NÄ° BAÅžLATMA FONKSÄ°YONU (SETUP)
# ==============================================================================
def setup_rag_chain():
    """RAG zincirini kurar ve dÃ¶ndÃ¼rÃ¼r."""
    
    # 1. API AnahtarÄ±nÄ± YÃ¼kleme 
    try:
        GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
        if not GEMINI_API_KEY:
             raise ValueError("API anahtarÄ± (GEMINI_API_KEY) Hugging Face Secrets'ta bulunamadÄ±.")
        os.environ["GEMINI_API_KEY"] = GEMINI_API_KEY 
    except Exception as e:
        print(f"HATA: API AnahtarÄ± yÃ¼klenemedi. Detay: {e}")
        return None
    
    # 2. Veri Setini Okuma ve DokÃ¼manlarÄ± OluÅŸturma
    try:
        DATA_FILE_PATH = 'erasmus_chatbot_dataset.csv' 
        df = pd.read_csv(DATA_FILE_PATH)
        
        documents_for_rag = []
        for index, row in df.iterrows():
            doc_content = f"Kategori: {row['kategori']}. Soru: {row['soru']}. Cevap: {row['cevap']}"
            documents_for_rag.append(Document(page_content=doc_content))
            
        texts = documents_for_rag 
            
    except Exception as e:
        print(f"HATA: Veri Seti Okuma veya DokÃ¼man OluÅŸturma BaÅŸarÄ±sÄ±z. Detay: {e}")
        return None

    # 3. GÃ¶mme (Embedding) Modeli TanÄ±mÄ±
    embeddings = GoogleGenerativeAIEmbeddings(
        model="text-embedding-004",
        google_api_key=GEMINI_API_KEY
    )
    
    # 4. VektÃ¶r VeritabanÄ± OluÅŸturma
    db = Chroma.from_documents(texts, embeddings)

    # 5. BÃ¼yÃ¼k Dil Modeli (LLM) TanÄ±mÄ±
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        temperature=0, 
        google_api_key=GEMINI_API_KEY
    )
    
    # 6. Prompt Åžablonunu Uygulama
    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_TEMPLATE),
        ("human", "{question}"),
    ])

    # 7. RetrievalQA Zinciri Kurulumu (RAG Pipeline)
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever(k=5), 
        return_source_documents=True,
        chain_type_kwargs={
             "prompt": qa_prompt,
             "document_variable_name": "context" 
        }
    )
    
    print("RAG Zinciri baÅŸarÄ±yla kuruldu ve optimize edildi.")
    return qa_chain

# Global olarak RAG zincirini bir kere yÃ¼kle
qa_chain = setup_rag_chain()

# ==============================================================================
# GRADIO CHATBOT CEVAP FONKSÄ°YONU
# ==============================================================================
def chatbot_response(message, history):
    
    if qa_chain is None:
        return "Chatbot kurulumu baÅŸarÄ±sÄ±z oldu. LÃ¼tfen loglarÄ± kontrol edin."

    response = qa_chain({"query": message})
    answer = response['result']
    source_docs = response['source_documents']
    
    # Kaynak Bilgisini HazÄ±rlama (ÅžeffaflÄ±k)
    sources_text = "\n\n***\n**Cevap KaynaklarÄ±:**\n"
    for doc in source_docs:
        content = doc.page_content.replace('Soru:', 'Soru: ').replace('. Cevap:', ' | Cevap: ')
        sources_text += f"*{content[:150]}...*\n"

    full_response = answer + sources_text
    
    return full_response

# ==============================================================================
# GRADIO ARAYÃœZ TANIMLAMASI
# ==============================================================================
iface = gr.ChatInterface(
    fn=chatbot_response,
    title="ðŸ‡ªðŸ‡º Erasmus RAGent Chatbot (Optimize EdilmiÅŸ)", 
    description="RAG (Retrieval Augmented Generation) ile Erasmus+ Bilgilendirme Sistemi. SorularÄ±nÄ±zÄ± sorabilirsiniz!",
    chatbot=gr.Chatbot(height=500),
    examples=["Erasmus'a kimler baÅŸvurabilir?", "Green Erasmus (YeÅŸil Erasmus) nedir?", "Hibe Ã¶demesi ne zaman yapÄ±lÄ±r?"],
    theme="soft"
)

if __name__ == "__main__":
    iface.launch()
