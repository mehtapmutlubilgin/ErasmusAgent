import gradio as gr
import os
import pandas as pd

# Gerekli kÃ¼tÃ¼phaneler (LangChain 0.3.x yapÄ±sÄ±na uygun)
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import ChatPromptTemplate


# ğŸ”¹ Sistem Prompt (gÃ¼ncel)
SYSTEM_TEMPLATE = """
Sen bir Erasmus+ bilgilendirme uzmanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorusuna sadece ve kesinlikle 
SAÄLANAN KAYNAK METÄ°NLERÄ° kullanarak cevap ver. 
EÄŸer kaynak metinlerde cevap yoksa, "Bu konuda elimde kesin bir bilgi bulunmamaktadÄ±r, 
lÃ¼tfen Ã¼niversitenizin UluslararasÄ± Ä°liÅŸkiler Ofisi'ne danÄ±ÅŸÄ±n." ÅŸeklinde cevapla. 
CevaplarÄ±nÄ± her zaman TÃ¼rkÃ§e olarak ve net bir dille sun.

KAYNAK: {context}
"""

# ğŸ”¹ RAG Zinciri Kurulumu
def setup_rag_chain():
    """RAG zincirini kurar ve dÃ¶ndÃ¼rÃ¼r."""
    try:
        GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
        if not GEMINI_API_KEY:
            raise ValueError("API anahtarÄ± (GEMINI_API_KEY) Hugging Face Secrets'ta bulunamadÄ±.")
    except Exception as e:
        print(f"HATA: API AnahtarÄ± yÃ¼klenemedi: {e}")
        return None
    
    try:
        DATA_FILE_PATH = 'erasmus_chatbot_dataset.csv' 
        df = pd.read_csv(DATA_FILE_PATH)
        df['kaynak_metin'] = "Kategori: " + df['kategori'] + ". Soru: " + df['soru'] + ". Cevap: " + df['cevap']
        documents_for_rag = df['kaynak_metin'].tolist()
    except Exception as e:
        print(f"HATA: Veri Seti Okuma BaÅŸarÄ±sÄ±z: {e}")
        return None

    # ğŸ”¹ Metinleri parÃ§alara ayÄ±r
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        length_function=len
    )
    texts = text_splitter.create_documents(documents_for_rag)

    # ğŸ”¹ Embedding ve veritabanÄ±
    embeddings = GoogleGenerativeAIEmbeddings(
        model="text-embedding-004",
        google_api_key=GEMINI_API_KEY
    )
    db = Chroma.from_documents(texts, embeddings)

    # ğŸ”¹ LLM (Gemini 2.5)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0,
        google_api_key=GEMINI_API_KEY
    )

    # ğŸ”¹ Prompt Åablonu
    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_TEMPLATE),
        ("human", "{question}"),
    ])

    # ğŸ”¹ RetrievalQA zinciri
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever(k=5),
        return_source_documents=True,
        chain_type_kwargs={
            "prompt": qa_prompt,
            "document_variable_name": "context"
        }
    )
    
    print("âœ… RAG Zinciri baÅŸarÄ±yla kuruldu.")
    return qa_chain


qa_chain = setup_rag_chain()


# ğŸ”¹ Chatbot cevabÄ±
def chatbot_response(message, history):
    if qa_chain is None:
        return "âŒ Chatbot kurulumu baÅŸarÄ±sÄ±z oldu. LÃ¼tfen API anahtarÄ±nÄ± kontrol edin."

    response = qa_chain({"query": message})
    answer = response['result']
    source_docs = response['source_documents']

    sources_text = "\n\n---\n**Kaynaklar:**\n"
    for doc in source_docs:
        content = doc.page_content.replace('Soru:', 'Soru: ').replace('. Cevap:', ' | Cevap: ')
        sources_text += f"- {content[:150]}...\n"

    return answer + sources_text


# ğŸ”¹ Gradio ArayÃ¼zÃ¼
iface = gr.ChatInterface(
    fn=chatbot_response,
    title="ğŸ‡ªğŸ‡º Erasmus RAGent Chatbot (Optimize EdilmiÅŸ)",
    description="RAG (Retrieval Augmented Generation) ile Erasmus+ Bilgilendirme Sistemi. SorularÄ±nÄ±zÄ± sorabilirsiniz!",
    chatbot=gr.Chatbot(height=500),
    examples=[
        "Erasmus'a kimler baÅŸvurabilir?",
        "Ã–ÄŸrenim sÃ¼resi ne kadardÄ±r?",
        "Hibesiz Erasmus yapÄ±labilir mi?"
    ],
    theme="soft"
)

if __name__ == "__main__":
    iface.launch()
