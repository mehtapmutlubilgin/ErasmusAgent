import gradio as gr
import os
import pandas as pd

# LangChain ÅŸema importu (DokÃ¼manlarÄ± oluÅŸturmak iÃ§in)
from langchain.schema import Document 

# Gerekli kÃ¼tÃ¼phaneler
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.vectorstores import Chroma # langchain_community'den otomatik Ã§ekilir
from langchain.chains import RetrievalQA
from langchain.prompts import ChatPromptTemplate 

# GÃœNCELLEME: Sistem Åablonu (System Prompt) - Biraz daha esnek
SYSTEM_TEMPLATE = """
Sen bir Erasmus+ bilgilendirme uzmanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorusuna, Ã¶ncelikle 
SAÄLANAN KAYNAK METÄ°NLERÄ° kullanarak cevap ver. 
CevaplarÄ±nÄ± her zaman TÃ¼rkÃ§e olarak ve net bir dille sun.

EÄŸer kaynak metinlerde cevap yoksa:
1. Konuyla ilgili genel, gÃ¼venilir bilgin varsa, "Kaynaklarda doÄŸrudan cevap bulunmamaktadÄ±r, ancak genel bilgi ÅŸÃ¶yledir:" diyerek cevap verebilirsin.
2. HiÃ§bir bilgin yoksa, "Bu konuda elimde yeterli ve kesin bir bilgi bulunmamaktadÄ±r, lÃ¼tfen Ã¼niversitenizin UluslararasÄ± Ä°liÅŸkiler Ofisi'ne danÄ±ÅŸÄ±n." ÅŸeklinde kibarca cevapla.

KAYNAK: {context}
"""

# RAG ZÄ°NCÄ°RÄ°NÄ° BAÅLATMA FONKSÄ°YONU
def setup_rag_chain():
    """RAG zincirini kurar ve dÃ¶ndÃ¼rÃ¼r."""
    
    # 1. API AnahtarÄ±nÄ± YÃ¼kleme (Hugging Face Secrets'tan)
    try:
        GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY")
        if not GEMINI_API_KEY:
             raise ValueError("API anahtarÄ± (GEMINI_API_KEY) Hugging Face Secrets'ta bulunamadÄ±.")
        os.environ["GEMINI_API_KEY"] = GEMINI_API_KEY
    except Exception as e:
        print(f"HATA: API AnahtarÄ± yÃ¼klenemedi: {e}")
        return None
    
    # 2. Veri Setini Okuma ve DokÃ¼manlarÄ± OluÅŸturma (GÃœNCEL YÃ–NTEM)
    try:
        DATA_FILE_PATH = 'erasmus_chatbot_dataset.csv' 
        df = pd.read_csv(DATA_FILE_PATH)
        
        # Her Soru-Cevap Ã§iftini tek bir LangChain Document objesi yap
        documents_for_rag = []
        for index, row in df.iterrows():
            doc_content = f"Kategori: {row['kategori']}. Soru: {row['soru']}. Cevap: {row['cevap']}"
            documents_for_rag.append(Document(page_content=doc_content))
            
    except Exception as e:
        print(f"HATA: Veri Seti Okuma veya DokÃ¼man OluÅŸturma BaÅŸarÄ±sÄ±z: {e}")
        return None

    # ArtÄ±k metin bÃ¶lmeye (splitting) gerek yok, her satÄ±r zaten tek dokÃ¼man
    texts = documents_for_rag

    # API anahtarÄ±nÄ± doÄŸrudan ilet
    embeddings = GoogleGenerativeAIEmbeddings(
        model="text-embedding-004",
        google_api_key=GEMINI_API_KEY
    )
    db = Chroma.from_documents(texts, embeddings) # DokÃ¼manlar doÄŸrudan vektÃ¶rleÅŸtirilir

    # API anahtarÄ±nÄ± doÄŸrudan ilet
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        temperature=0, 
        google_api_key=GEMINI_API_KEY
    )
    
    # Prompt Åablonunu OluÅŸturma
    qa_prompt = ChatPromptTemplate.from_messages([
        ("system", SYSTEM_TEMPLATE),
        ("human", "{question}"),
    ])

    # RetrievalQA Zinciri
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=db.as_retriever(k=5), # k=5 (5 dokÃ¼man Ã§ek) kullanmaya devam ediyoruz
        return_source_documents=True,
        chain_type_kwargs={
             "prompt": qa_prompt,
             "document_variable_name": "context"
        }
    )
    
    print("RAG Zinciri baÅŸarÄ±yla kuruldu ve optimize edildi.")
    return qa_chain

# Global olarak RAG zincirini bir kere yÃ¼kle
qa_chain = setup_rag_chain()

def chatbot_response(message, history):
    """Gelen mesajÄ± RAG zincirine gÃ¶nderir ve cevabÄ± dÃ¶ndÃ¼rÃ¼r."""
    
    if qa_chain is None:
        return "Chatbot kurulumu baÅŸarÄ±sÄ±z oldu. LÃ¼tfen Hugging Face Secrets ve loglarÄ± kontrol edin."

    response = qa_chain({"query": message})
    answer = response['result']
    source_docs = response['source_documents']
    
    # Kaynak Bilgisini HazÄ±rlama
    sources_text = "\n\n***\n**Kaynaklar:**\n"
    for doc in source_docs:
        # Kaynak metin formatÄ±nÄ± daha anlaÅŸÄ±lÄ±r hale getir
        content = doc.page_content.replace('Soru:', 'Soru: ').replace('. Cevap:', ' | Cevap: ')
        sources_text += f"*{content[:150]}...*\n"

    full_response = answer + sources_text
    
    return full_response

# GRADIO ARAYÃœZÃœ
iface = gr.ChatInterface(
    fn=chatbot_response,
    title="ğŸ‡ªğŸ‡º Erasmus RAGent Chatbot (Optimize EdilmiÅŸ)", 
    description="RAG (Retrieval Augmented Generation) ile Erasmus+ Bilgilendirme Sistemi. SorularÄ±nÄ±zÄ± sorabilirsiniz!",
    chatbot=gr.Chatbot(height=500),
    examples=["Erasmus'a kimler baÅŸvurabilir?", "Ã–ÄŸrenim sÃ¼resi ne kadardÄ±r?", "Hibesiz Erasmus yapÄ±labilir mi?"],
    theme="soft"
)

if __name__ == "__main__":
    iface.launch()
